{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Credit Card Fraud.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manojec054/Assignment/blob/master/Copy_of_Credit_Card_Fraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7c8C6JhjMGq"
      },
      "source": [
        "## Credit Card Fraud\n",
        "\n",
        "Data Has been sourced from Kaggle\n",
        "\n",
        "Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/downloads/creditcardfraud.zip\n",
        "\n",
        "\n",
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPlR2yyAjvPb"
      },
      "source": [
        "Our task is to make a simple DL classifer to correctly classify frauds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8WLTlbki--7"
      },
      "source": [
        "# Starting with useful imports\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fra2tKmfwxd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227b7383-f7e3-456f-b256-5cef67d89cab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6tCHJXRzJWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba3233e-8716-437b-9e0f-a18ec643f20f"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf6gG-oKk0xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c43aac7-5344-47f9-8fdd-a61259352b2d"
      },
      "source": [
        "fname = 'My Drive/Data/UCI_Credit_Card.csv'\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "  for i, line in enumerate(f):\n",
        "    if i == 0:\n",
        "      print('HEADER:', line.strip())\n",
        "      continue  # Skip header\n",
        "    fields = line.strip().split(',')\n",
        "    all_features.append([float(v.replace('\"', '')) for v in fields[:-1]])\n",
        "    all_targets.append([int(fields[-1].replace('\"', ''))])\n",
        "    if i == 1:\n",
        "      print('EXAMPLE FEATURES:', all_features[-1])\n",
        "    \n",
        "features = np.array(all_features, dtype='float32')\n",
        "targets = np.array(all_targets, dtype='uint8')\n",
        "print('features.shape:', features.shape)\n",
        "print('targets.shape:', targets.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEADER: \"ID\",\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\",\"default.payment.next.month\"\n",
            "EXAMPLE FEATURES: [1.0, 20000.0, 2.0, 2.0, 1.0, 24.0, 2.0, 2.0, -1.0, -1.0, -2.0, -2.0, 3913.0, 3102.0, 689.0, 0.0, 0.0, 0.0, 0.0, 689.0, 0.0, 0.0, 0.0, 0.0]\n",
            "features.shape: (30000, 24)\n",
            "targets.shape: (30000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "U9U3gW7owGPS",
        "outputId": "dff3e731-ef22-40d9-acfc-fa90a1a34016"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "df = pd.read_csv('My Drive/Data/UCI_Credit_Card.csv')\r\n",
        "df.rename(columns={'default.payment.next.month':'target', 'PAY_0':'PAY_1'}, inplace=True)\r\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_1</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>3913.0</td>\n",
              "      <td>3102.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>1725.0</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>3272.0</td>\n",
              "      <td>3455.0</td>\n",
              "      <td>3261.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29239.0</td>\n",
              "      <td>14027.0</td>\n",
              "      <td>13559.0</td>\n",
              "      <td>14331.0</td>\n",
              "      <td>14948.0</td>\n",
              "      <td>15549.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46990.0</td>\n",
              "      <td>48233.0</td>\n",
              "      <td>49291.0</td>\n",
              "      <td>28314.0</td>\n",
              "      <td>28959.0</td>\n",
              "      <td>29547.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8617.0</td>\n",
              "      <td>5670.0</td>\n",
              "      <td>35835.0</td>\n",
              "      <td>20940.0</td>\n",
              "      <td>19146.0</td>\n",
              "      <td>19131.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  LIMIT_BAL  SEX  EDUCATION  ...  PAY_AMT4  PAY_AMT5  PAY_AMT6  target\n",
              "0   1    20000.0    2          2  ...       0.0       0.0       0.0       1\n",
              "1   2   120000.0    2          2  ...    1000.0       0.0    2000.0       1\n",
              "2   3    90000.0    2          2  ...    1000.0    1000.0    5000.0       0\n",
              "3   4    50000.0    2          2  ...    1100.0    1069.0    1000.0       0\n",
              "4   5    50000.0    1          2  ...    9000.0     689.0     679.0       0\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "nA5voh2Iywwv",
        "outputId": "af0cd633-71f8-4394-cd1b-503db3da5e27"
      },
      "source": [
        "display(df.EDUCATION.value_counts())\r\n",
        "fil = (df.EDUCATION == 5) | (df.EDUCATION == 6) | (df.EDUCATION == 0)\r\n",
        "df.loc[fil, 'EDUCATION'] = 4\r\n",
        "df.EDUCATION.value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2    14030\n",
              "1    10585\n",
              "3     4917\n",
              "5      280\n",
              "4      123\n",
              "6       51\n",
              "0       14\n",
              "Name: EDUCATION, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    14030\n",
              "1    10585\n",
              "3     4917\n",
              "4      468\n",
              "Name: EDUCATION, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmIfj86o0FV2",
        "outputId": "77838d6d-5c12-4a41-f7fc-ae5603e36c56"
      },
      "source": [
        "df.loc[df.MARRIAGE == 0, 'MARRIAGE'] = 3\r\n",
        "df.MARRIAGE.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    15964\n",
              "1    13659\n",
              "3      377\n",
              "Name: MARRIAGE, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp9K-TjR2O-8",
        "outputId": "4c2661db-9fc1-4f37-a0e6-4143cb32cdb4"
      },
      "source": [
        "df.target.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23364\n",
              "1     6636\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmBdaDS46Yvf"
      },
      "source": [
        "df['AgeBin'] = 0 #creates a column of 0\r\n",
        "df.loc[((df['AGE'] > 20) & (df['AGE'] < 30)) , 'AgeBin'] = 1\r\n",
        "df.loc[((df['AGE'] >= 30) & (df['AGE'] < 40)) , 'AgeBin'] = 2\r\n",
        "df.loc[((df['AGE'] >= 40) & (df['AGE'] < 50)) , 'AgeBin'] = 3\r\n",
        "df.loc[((df['AGE'] >= 50) & (df['AGE'] < 60)) , 'AgeBin'] = 4\r\n",
        "df.loc[((df['AGE'] >= 60) & (df['AGE'] < 70)) , 'AgeBin'] = 5\r\n",
        "df.loc[((df['AGE'] >= 70) & (df['AGE'] < 81)) , 'AgeBin'] = 6\r\n",
        "df.loc[(df['AgeBin'] == 6) , 'AgeBin'] = 5"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxJk_hqD6mpl"
      },
      "source": [
        "df['SE_MA_2'] = 0\r\n",
        "df.loc[((df.SEX == 1) & (df.MARRIAGE == 1)) , 'SE_MA_2'] = 1 # Married male \r\n",
        "df.loc[((df.SEX == 1) & (df.MARRIAGE == 2)) , 'SE_MA_2'] = 2 # Single male \r\n",
        "df.loc[((df.SEX == 1) & (df.MARRIAGE == 3)) , 'SE_MA_2'] = 3 \r\n",
        "df.loc[((df.SEX == 2) & (df.MARRIAGE == 1)) , 'SE_MA_2'] = 4 \r\n",
        "df.loc[((df.SEX == 2) & (df.MARRIAGE == 2)) , 'SE_MA_2'] = 5 \r\n",
        "df.loc[((df.SEX == 2) & (df.MARRIAGE == 3)) , 'SE_MA_2'] = 6 "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hILkXojL6tLk"
      },
      "source": [
        "df['SE_AG'] = 0\r\n",
        "df.loc[((df.SEX == 1) & (df.AgeBin == 1)) , 'SE_AG'] = 1 #man in 20's\r\n",
        "df.loc[((df.SEX == 1) & (df.AgeBin == 2)) , 'SE_AG'] = 2 #man in 30's\r\n",
        "df.loc[((df.SEX == 1) & (df.AgeBin == 3)) , 'SE_AG'] = 3 #man in 40's\r\n",
        "df.loc[((df.SEX == 1) & (df.AgeBin == 4)) , 'SE_AG'] = 4 #man in 50's\r\n",
        "df.loc[((df.SEX == 1) & (df.AgeBin == 5)) , 'SE_AG'] = 5 #man in 60's and above\r\n",
        "df.loc[((df.SEX == 2) & (df.AgeBin == 1)) , 'SE_AG'] = 6 #woman in 20's\r\n",
        "df.loc[((df.SEX == 2) & (df.AgeBin == 2)) , 'SE_AG'] = 7 #woman in 30's\r\n",
        "df.loc[((df.SEX == 2) & (df.AgeBin == 3)) , 'SE_AG'] = 8 #woman in 40's\r\n",
        "df.loc[((df.SEX == 2) & (df.AgeBin == 4)) , 'SE_AG'] = 9 #woman in 50's\r\n",
        "df.loc[((df.SEX == 2) & (df.AgeBin == 5)) , 'SE_AG'] = 10 #woman in 60's and above"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5zuFqYO60Ee"
      },
      "source": [
        "df['Proximity_6'] = (df.LIMIT_BAL - df.BILL_AMT6) / df.LIMIT_BAL\r\n",
        "df['Proximity_5'] = (df.LIMIT_BAL - df.BILL_AMT5) / df.LIMIT_BAL\r\n",
        "df['Proximity_4'] = (df.LIMIT_BAL - df.BILL_AMT4) / df.LIMIT_BAL\r\n",
        "df['Proximity_3'] = (df.LIMIT_BAL - df.BILL_AMT3) / df.LIMIT_BAL\r\n",
        "df['Proximity_2'] = (df.LIMIT_BAL - df.BILL_AMT2) / df.LIMIT_BAL\r\n",
        "df['Proximity_1'] = (df.LIMIT_BAL - df.BILL_AMT1) / df.LIMIT_BAL"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Vdrz9vSw2K6d",
        "outputId": "e3942fbc-5dd8-4073-f9fc-d908da30b068"
      },
      "source": [
        "from sklearn.utils import resample\r\n",
        "# Upsample minority class\r\n",
        "upsampled = resample(df[df.target == 1], \r\n",
        "                                 replace=True,     # sample with replacement\r\n",
        "                                 n_samples=23364,    # to match majority class\r\n",
        "                                 random_state=587) # reproducible results\r\n",
        "# Combine majority class with upsampled minority class\r\n",
        "upsampled_df = pd.concat([df[df.target == 0], upsampled])\r\n",
        "# Display new class counts\r\n",
        "display(upsampled_df.target.value_counts())\r\n",
        "upsampled_df.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1    23364\n",
              "0    23364\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46728, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "TKH_oPIt43M-",
        "outputId": "049bfa71-a6a0-4730-db68-95e4e7623303"
      },
      "source": [
        "from sklearn.utils import resample\r\n",
        "# Downsample minority class\r\n",
        "down_sampled = resample(df[df.target == 0], \r\n",
        "                                 replace=True,     # sample with replacement\r\n",
        "                                 n_samples=6636,    # to match majority class\r\n",
        "                                 random_state=587) # reproducible results\r\n",
        "# Combine majority class with upsampled minority class\r\n",
        "down_df = pd.concat([df[df.target == 1], down_sampled])\r\n",
        "# Display new class counts\r\n",
        "display(down_df.target.value_counts())\r\n",
        "down_df.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1    6636\n",
              "0    6636\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13272, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvVYy7my49sv"
      },
      "source": [
        "\r\n",
        "df_final = upsampled_df\r\n",
        "#df_final = down_df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "jKYQlbw97T7f",
        "outputId": "a5261e8e-d919-431f-e914-4596b510634c"
      },
      "source": [
        "df_final.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_1</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>PAY_5</th>\n",
              "      <th>PAY_6</th>\n",
              "      <th>BILL_AMT1</th>\n",
              "      <th>BILL_AMT2</th>\n",
              "      <th>BILL_AMT3</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>target</th>\n",
              "      <th>AgeBin</th>\n",
              "      <th>SE_MA_2</th>\n",
              "      <th>SE_AG</th>\n",
              "      <th>Proximity_6</th>\n",
              "      <th>Proximity_5</th>\n",
              "      <th>Proximity_4</th>\n",
              "      <th>Proximity_3</th>\n",
              "      <th>Proximity_2</th>\n",
              "      <th>Proximity_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29239.0</td>\n",
              "      <td>14027.0</td>\n",
              "      <td>13559.0</td>\n",
              "      <td>14331.0</td>\n",
              "      <td>14948.0</td>\n",
              "      <td>15549.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0.827233</td>\n",
              "      <td>0.833911</td>\n",
              "      <td>0.840767</td>\n",
              "      <td>0.849344</td>\n",
              "      <td>0.844144</td>\n",
              "      <td>0.675122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46990.0</td>\n",
              "      <td>48233.0</td>\n",
              "      <td>49291.0</td>\n",
              "      <td>28314.0</td>\n",
              "      <td>28959.0</td>\n",
              "      <td>29547.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0.409060</td>\n",
              "      <td>0.420820</td>\n",
              "      <td>0.433720</td>\n",
              "      <td>0.014180</td>\n",
              "      <td>0.035340</td>\n",
              "      <td>0.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8617.0</td>\n",
              "      <td>5670.0</td>\n",
              "      <td>35835.0</td>\n",
              "      <td>20940.0</td>\n",
              "      <td>19146.0</td>\n",
              "      <td>19131.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.617380</td>\n",
              "      <td>0.617080</td>\n",
              "      <td>0.581200</td>\n",
              "      <td>0.283300</td>\n",
              "      <td>0.886600</td>\n",
              "      <td>0.827660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64400.0</td>\n",
              "      <td>57069.0</td>\n",
              "      <td>57608.0</td>\n",
              "      <td>19394.0</td>\n",
              "      <td>19619.0</td>\n",
              "      <td>20024.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>1815.0</td>\n",
              "      <td>657.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.599520</td>\n",
              "      <td>0.607620</td>\n",
              "      <td>0.612120</td>\n",
              "      <td>-0.152160</td>\n",
              "      <td>-0.141380</td>\n",
              "      <td>-0.288000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>500000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>367965.0</td>\n",
              "      <td>412023.0</td>\n",
              "      <td>445007.0</td>\n",
              "      <td>542653.0</td>\n",
              "      <td>483003.0</td>\n",
              "      <td>473944.0</td>\n",
              "      <td>55000.0</td>\n",
              "      <td>40000.0</td>\n",
              "      <td>38000.0</td>\n",
              "      <td>20239.0</td>\n",
              "      <td>13750.0</td>\n",
              "      <td>13770.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.052112</td>\n",
              "      <td>0.033994</td>\n",
              "      <td>-0.085306</td>\n",
              "      <td>0.109986</td>\n",
              "      <td>0.175954</td>\n",
              "      <td>0.264070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  LIMIT_BAL  SEX  ...  Proximity_3  Proximity_2  Proximity_1\n",
              "2   3    90000.0    2  ...     0.849344     0.844144     0.675122\n",
              "3   4    50000.0    2  ...     0.014180     0.035340     0.060200\n",
              "4   5    50000.0    1  ...     0.283300     0.886600     0.827660\n",
              "5   6    50000.0    1  ...    -0.152160    -0.141380    -0.288000\n",
              "6   7   500000.0    1  ...     0.109986     0.175954     0.264070\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpTB5PuY4AkY"
      },
      "source": [
        "X = df_final.drop(['target','ID'], axis=1) \r\n",
        "y = df_final.target"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0-LCfwnwlto"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tdNslXnxCRg"
      },
      "source": [
        "train_features = X_train.to_numpy()\r\n",
        "train_targets = y_train.to_numpy().reshape(-1, 1)\r\n",
        "test_features = X_test.to_numpy()\r\n",
        "test_targets = y_test.to_numpy().reshape(-1, 1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7PMGXdEk53Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9dea4d-6016-4a86-c89a-009189c3568f"
      },
      "source": [
        "num_test_samples = int(len(features) * 0.2)\n",
        "#train_features = features[:-num_test_samples]\n",
        "#train_targets = targets[:-num_test_samples]\n",
        "#test_features = features[-num_test_samples:]\n",
        "#test_targets = targets[-num_test_samples:]\n",
        "print('Number of training samples:', len(train_features))\n",
        "print('Number of test samples:', len(test_features))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 37382\n",
            "Number of test samples: 9346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgHaMfUtlOZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ab091d-99a6-4ea8-e570-2b3bef986325"
      },
      "source": [
        "counts = np.bincount( train_targets[:, 0])\n",
        "print('Number of positive samples in training data: {} ({:.2f}% of total)'.format(counts[1], 100 * float(counts[1]) / len(train_targets)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive samples in training data: 18715 (50.06% of total)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7uHmVq5txZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9dd7f0-c4db-4965-bb78-d151504de054"
      },
      "source": [
        "counts = np.bincount(test_targets[:, 0])\n",
        "print('Number of positive samples in testing data: {} ({:.2f}% of total)'.format(counts[1], 100 * float(counts[1]) / len(test_targets)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive samples in testing data: 4649 (49.74% of total)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgYkz7W3lX_a"
      },
      "source": [
        "mean = np.mean(train_features, axis=0)\n",
        "train_features -= mean\n",
        "test_features -= mean\n",
        "std = np.std(train_features, axis=0)\n",
        "train_features /= std\n",
        "test_features /= std"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8R0Ga_Ut-xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea111c00-56d7-470a-805f-8febbcb68c53"
      },
      "source": [
        "train_features.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37382, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISKRObCClfoF"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import  Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation=tf.nn.tanh))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation=tf.nn.tanh))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "# your code here"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOEc9js1qACK"
      },
      "source": [
        "#model.fit(train_features, train_targets, epochs=100, batch_size=100)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-93q37XliPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01667ead-3c3e-4ee6-8da0-5e60033f1f5d"
      },
      "source": [
        "metrics = [keras.metrics.FalseNegatives(name='fn'),\n",
        "           keras.metrics.FalsePositives(name='fp'),\n",
        "           keras.metrics.TrueNegatives(name='tn'),\n",
        "           keras.metrics.TruePositives(name='tp'),\n",
        "           keras.metrics.Precision(name='precision'),\n",
        "           keras.metrics.Recall(name='recall'),\n",
        "           keras.metrics.Accuracy(name='accuracy')]\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-2),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=metrics)\n",
        "\n",
        "#callbacks = [keras.callbacks.ModelCheckpoint('fraud_model_at_epoch_{epoch}.h5')]\n",
        "class_weight = {0: 1, 1: 200}\n",
        "\n",
        "model.fit(train_features, train_targets,\n",
        "          batch_size=4096, epochs=100, verbose=1, validation_data=(test_features, test_targets), class_weight=class_weight)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 3s 103ms/step - loss: 23.2571 - fn: 0.0000e+00 - fp: 11747.3636 - tn: 0.0000e+00 - tp: 11805.7273 - precision: 0.5012 - recall: 1.0000 - accuracy: 0.5012 - val_loss: 4.7408 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 3.9199 - fn: 0.0000e+00 - fp: 11732.0000 - tn: 0.0000e+00 - tp: 11821.0909 - precision: 0.5026 - recall: 1.0000 - accuracy: 0.5026 - val_loss: 3.5042 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.2839 - fn: 0.0000e+00 - fp: 11745.2727 - tn: 0.0000e+00 - tp: 11807.8182 - precision: 0.5025 - recall: 1.0000 - accuracy: 0.5025 - val_loss: 3.0376 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.1351 - fn: 0.0000e+00 - fp: 11769.7273 - tn: 0.0000e+00 - tp: 11783.3636 - precision: 0.4998 - recall: 1.0000 - accuracy: 0.4998 - val_loss: 2.6207 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 3.0000 - fn: 0.0000e+00 - fp: 11745.4545 - tn: 0.0000e+00 - tp: 11807.6364 - precision: 0.5016 - recall: 1.0000 - accuracy: 0.5016 - val_loss: 2.4598 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.9755 - fn: 0.0000e+00 - fp: 11764.6364 - tn: 0.0000e+00 - tp: 11788.4545 - precision: 0.4996 - recall: 1.0000 - accuracy: 0.4996 - val_loss: 2.4361 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.9443 - fn: 0.0000e+00 - fp: 11756.8182 - tn: 0.0000e+00 - tp: 11796.2727 - precision: 0.5006 - recall: 1.0000 - accuracy: 0.5006 - val_loss: 2.4262 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.9346 - fn: 0.0000e+00 - fp: 11795.7273 - tn: 0.0000e+00 - tp: 11757.3636 - precision: 0.4982 - recall: 1.0000 - accuracy: 0.4982 - val_loss: 2.4613 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.9083 - fn: 0.0000e+00 - fp: 11723.0000 - tn: 0.0000e+00 - tp: 11830.0909 - precision: 0.5024 - recall: 1.0000 - accuracy: 0.5024 - val_loss: 2.3816 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.9111 - fn: 0.0000e+00 - fp: 11750.9091 - tn: 0.0000e+00 - tp: 11802.1818 - precision: 0.5016 - recall: 1.0000 - accuracy: 0.5016 - val_loss: 2.5050 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8962 - fn: 0.0000e+00 - fp: 11725.6364 - tn: 0.0000e+00 - tp: 11827.4545 - precision: 0.5042 - recall: 1.0000 - accuracy: 0.5042 - val_loss: 2.5237 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.9187 - fn: 0.0000e+00 - fp: 11791.8182 - tn: 0.0000e+00 - tp: 11761.2727 - precision: 0.4974 - recall: 1.0000 - accuracy: 0.4974 - val_loss: 2.3692 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.9135 - fn: 0.0000e+00 - fp: 11785.1818 - tn: 0.0000e+00 - tp: 11767.9091 - precision: 0.4993 - recall: 1.0000 - accuracy: 0.4993 - val_loss: 2.4139 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8861 - fn: 0.0000e+00 - fp: 11751.1818 - tn: 0.0000e+00 - tp: 11801.9091 - precision: 0.5008 - recall: 1.0000 - accuracy: 0.5008 - val_loss: 2.4073 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8926 - fn: 0.0000e+00 - fp: 11755.1818 - tn: 0.0000e+00 - tp: 11797.9091 - precision: 0.5005 - recall: 1.0000 - accuracy: 0.5005 - val_loss: 2.4698 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8849 - fn: 0.0000e+00 - fp: 11745.8182 - tn: 0.0000e+00 - tp: 11807.2727 - precision: 0.5012 - recall: 1.0000 - accuracy: 0.5012 - val_loss: 2.4117 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8711 - fn: 0.0000e+00 - fp: 11750.3636 - tn: 0.0000e+00 - tp: 11802.7273 - precision: 0.5019 - recall: 1.0000 - accuracy: 0.5019 - val_loss: 2.3698 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8720 - fn: 0.0000e+00 - fp: 11765.1818 - tn: 0.0000e+00 - tp: 11787.9091 - precision: 0.5000 - recall: 1.0000 - accuracy: 0.5000 - val_loss: 2.3350 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8691 - fn: 0.0000e+00 - fp: 11779.0909 - tn: 0.0000e+00 - tp: 11774.0000 - precision: 0.4989 - recall: 1.0000 - accuracy: 0.4989 - val_loss: 2.4223 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8510 - fn: 0.0000e+00 - fp: 11717.6364 - tn: 0.0000e+00 - tp: 11835.4545 - precision: 0.5038 - recall: 1.0000 - accuracy: 0.5038 - val_loss: 2.3923 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8497 - fn: 0.0000e+00 - fp: 11732.6364 - tn: 0.0000e+00 - tp: 11820.4545 - precision: 0.5024 - recall: 1.0000 - accuracy: 0.5024 - val_loss: 2.3612 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8517 - fn: 0.0000e+00 - fp: 11740.1818 - tn: 0.0000e+00 - tp: 11812.9091 - precision: 0.5021 - recall: 1.0000 - accuracy: 0.5021 - val_loss: 2.4434 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8599 - fn: 0.0000e+00 - fp: 11753.4545 - tn: 0.0000e+00 - tp: 11799.6364 - precision: 0.5013 - recall: 1.0000 - accuracy: 0.5013 - val_loss: 2.2936 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8664 - fn: 0.0000e+00 - fp: 11735.0000 - tn: 0.0000e+00 - tp: 11818.0909 - precision: 0.5024 - recall: 1.0000 - accuracy: 0.5024 - val_loss: 2.4236 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8795 - fn: 0.0000e+00 - fp: 11808.4545 - tn: 0.0000e+00 - tp: 11744.6364 - precision: 0.4966 - recall: 1.0000 - accuracy: 0.4966 - val_loss: 2.3876 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8631 - fn: 0.0000e+00 - fp: 11817.0909 - tn: 0.0000e+00 - tp: 11736.0000 - precision: 0.4973 - recall: 1.0000 - accuracy: 0.4973 - val_loss: 2.3792 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8368 - fn: 0.0000e+00 - fp: 11729.4545 - tn: 0.0000e+00 - tp: 11823.6364 - precision: 0.5036 - recall: 1.0000 - accuracy: 0.5036 - val_loss: 2.2411 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8413 - fn: 0.0000e+00 - fp: 11768.8182 - tn: 0.0000e+00 - tp: 11784.2727 - precision: 0.5007 - recall: 1.0000 - accuracy: 0.5007 - val_loss: 2.4440 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8229 - fn: 0.0000e+00 - fp: 11785.4545 - tn: 0.0000e+00 - tp: 11767.6364 - precision: 0.4994 - recall: 1.0000 - accuracy: 0.4994 - val_loss: 2.3071 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8253 - fn: 0.0000e+00 - fp: 11719.1818 - tn: 0.0000e+00 - tp: 11833.9091 - precision: 0.5033 - recall: 1.0000 - accuracy: 0.5033 - val_loss: 2.2974 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8221 - fn: 0.0000e+00 - fp: 11751.3636 - tn: 0.0000e+00 - tp: 11801.7273 - precision: 0.5010 - recall: 1.0000 - accuracy: 0.5010 - val_loss: 2.4701 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8399 - fn: 0.0000e+00 - fp: 11761.6364 - tn: 0.0000e+00 - tp: 11791.4545 - precision: 0.5007 - recall: 1.0000 - accuracy: 0.5007 - val_loss: 2.3676 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8288 - fn: 0.0000e+00 - fp: 11742.5455 - tn: 0.0000e+00 - tp: 11810.5455 - precision: 0.5024 - recall: 1.0000 - accuracy: 0.5024 - val_loss: 2.3551 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8411 - fn: 0.0000e+00 - fp: 11800.0909 - tn: 0.0000e+00 - tp: 11753.0000 - precision: 0.4979 - recall: 1.0000 - accuracy: 0.4979 - val_loss: 2.3966 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8123 - fn: 0.0000e+00 - fp: 11706.3636 - tn: 0.0000e+00 - tp: 11846.7273 - precision: 0.5045 - recall: 1.0000 - accuracy: 0.5045 - val_loss: 2.3759 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8323 - fn: 0.0000e+00 - fp: 11758.5455 - tn: 0.0000e+00 - tp: 11794.5455 - precision: 0.5000 - recall: 1.0000 - accuracy: 0.5000 - val_loss: 2.3307 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8365 - fn: 0.0000e+00 - fp: 11772.0000 - tn: 0.0000e+00 - tp: 11781.0909 - precision: 0.5004 - recall: 1.0000 - accuracy: 0.5004 - val_loss: 2.3359 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8230 - fn: 0.0000e+00 - fp: 11744.5455 - tn: 0.0000e+00 - tp: 11808.5455 - precision: 0.5020 - recall: 1.0000 - accuracy: 0.5020 - val_loss: 2.4820 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8447 - fn: 0.0000e+00 - fp: 11761.3636 - tn: 0.0000e+00 - tp: 11791.7273 - precision: 0.5004 - recall: 1.0000 - accuracy: 0.5004 - val_loss: 2.6109 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8542 - fn: 0.0000e+00 - fp: 11731.1818 - tn: 0.0000e+00 - tp: 11821.9091 - precision: 0.5030 - recall: 1.0000 - accuracy: 0.5030 - val_loss: 2.4911 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8545 - fn: 0.0000e+00 - fp: 11785.0000 - tn: 0.0000e+00 - tp: 11768.0909 - precision: 0.4985 - recall: 1.0000 - accuracy: 0.4985 - val_loss: 2.3076 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8378 - fn: 0.0000e+00 - fp: 11733.6364 - tn: 0.0000e+00 - tp: 11819.4545 - precision: 0.5030 - recall: 1.0000 - accuracy: 0.5030 - val_loss: 2.2381 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.8307 - fn: 0.0000e+00 - fp: 11730.9091 - tn: 0.0000e+00 - tp: 11822.1818 - precision: 0.5033 - recall: 1.0000 - accuracy: 0.5033 - val_loss: 2.3669 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 2.8148 - fn: 0.0000e+00 - fp: 11743.6364 - tn: 0.0000e+00 - tp: 11809.4545 - precision: 0.5026 - recall: 1.0000 - accuracy: 0.5026 - val_loss: 2.3927 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7992 - fn: 0.0000e+00 - fp: 11751.3636 - tn: 0.0000e+00 - tp: 11801.7273 - precision: 0.5013 - recall: 1.0000 - accuracy: 0.5013 - val_loss: 2.3452 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8161 - fn: 0.0000e+00 - fp: 11787.4545 - tn: 0.0000e+00 - tp: 11765.6364 - precision: 0.4988 - recall: 1.0000 - accuracy: 0.4988 - val_loss: 2.3352 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8079 - fn: 0.0000e+00 - fp: 11789.0909 - tn: 0.0000e+00 - tp: 11764.0000 - precision: 0.4986 - recall: 1.0000 - accuracy: 0.4986 - val_loss: 2.4974 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8257 - fn: 0.0000e+00 - fp: 11783.6364 - tn: 0.0000e+00 - tp: 11769.4545 - precision: 0.5009 - recall: 1.0000 - accuracy: 0.5009 - val_loss: 2.3769 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8097 - fn: 0.0000e+00 - fp: 11735.8182 - tn: 0.0000e+00 - tp: 11817.2727 - precision: 0.5025 - recall: 1.0000 - accuracy: 0.5025 - val_loss: 2.2069 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8298 - fn: 0.0000e+00 - fp: 11709.9091 - tn: 0.0000e+00 - tp: 11843.1818 - precision: 0.5039 - recall: 1.0000 - accuracy: 0.5039 - val_loss: 2.2876 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.7974 - fn: 0.0000e+00 - fp: 11753.0000 - tn: 0.0000e+00 - tp: 11800.0909 - precision: 0.5008 - recall: 1.0000 - accuracy: 0.5008 - val_loss: 2.3306 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7860 - fn: 0.0000e+00 - fp: 11752.4545 - tn: 0.0000e+00 - tp: 11800.6364 - precision: 0.5009 - recall: 1.0000 - accuracy: 0.5009 - val_loss: 2.2969 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8157 - fn: 0.0000e+00 - fp: 11762.7273 - tn: 0.0000e+00 - tp: 11790.3636 - precision: 0.5007 - recall: 1.0000 - accuracy: 0.5007 - val_loss: 2.5166 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8188 - fn: 0.0000e+00 - fp: 11741.5455 - tn: 0.0000e+00 - tp: 11811.5455 - precision: 0.5017 - recall: 1.0000 - accuracy: 0.5017 - val_loss: 2.4193 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7854 - fn: 0.0000e+00 - fp: 11786.3636 - tn: 0.0000e+00 - tp: 11766.7273 - precision: 0.4985 - recall: 1.0000 - accuracy: 0.4985 - val_loss: 2.3260 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7823 - fn: 0.0000e+00 - fp: 11793.8182 - tn: 0.0000e+00 - tp: 11759.2727 - precision: 0.5002 - recall: 1.0000 - accuracy: 0.5002 - val_loss: 2.4384 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7652 - fn: 0.0000e+00 - fp: 11744.3636 - tn: 0.0000e+00 - tp: 11808.7273 - precision: 0.5016 - recall: 1.0000 - accuracy: 0.5016 - val_loss: 2.2898 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.7664 - fn: 0.0000e+00 - fp: 11756.7273 - tn: 0.0000e+00 - tp: 11796.3636 - precision: 0.5012 - recall: 1.0000 - accuracy: 0.5012 - val_loss: 2.3475 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7927 - fn: 0.0000e+00 - fp: 11747.7273 - tn: 0.0000e+00 - tp: 11805.3636 - precision: 0.5016 - recall: 1.0000 - accuracy: 0.5016 - val_loss: 2.2988 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8256 - fn: 0.0000e+00 - fp: 11761.4545 - tn: 0.0000e+00 - tp: 11791.6364 - precision: 0.5004 - recall: 1.0000 - accuracy: 0.5004 - val_loss: 2.4221 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8241 - fn: 0.0000e+00 - fp: 11748.2727 - tn: 0.0000e+00 - tp: 11804.8182 - precision: 0.5009 - recall: 1.0000 - accuracy: 0.5009 - val_loss: 2.4562 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8022 - fn: 0.0000e+00 - fp: 11723.8182 - tn: 0.0000e+00 - tp: 11829.2727 - precision: 0.5045 - recall: 1.0000 - accuracy: 0.5045 - val_loss: 2.3787 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8307 - fn: 0.0000e+00 - fp: 11796.0909 - tn: 0.0000e+00 - tp: 11757.0000 - precision: 0.4988 - recall: 1.0000 - accuracy: 0.4988 - val_loss: 2.5814 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8673 - fn: 0.0000e+00 - fp: 11787.3636 - tn: 0.0000e+00 - tp: 11765.7273 - precision: 0.4993 - recall: 1.0000 - accuracy: 0.4993 - val_loss: 2.3783 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8274 - fn: 0.0000e+00 - fp: 11781.0000 - tn: 0.0000e+00 - tp: 11772.0909 - precision: 0.4999 - recall: 1.0000 - accuracy: 0.4999 - val_loss: 2.3803 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8247 - fn: 0.0000e+00 - fp: 11789.0909 - tn: 0.0000e+00 - tp: 11764.0000 - precision: 0.4985 - recall: 1.0000 - accuracy: 0.4985 - val_loss: 2.3425 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8221 - fn: 0.0000e+00 - fp: 11748.5455 - tn: 0.0000e+00 - tp: 11804.5455 - precision: 0.5017 - recall: 1.0000 - accuracy: 0.5017 - val_loss: 2.2776 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8262 - fn: 0.0000e+00 - fp: 11798.1818 - tn: 0.0000e+00 - tp: 11754.9091 - precision: 0.4961 - recall: 1.0000 - accuracy: 0.4961 - val_loss: 2.3495 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8006 - fn: 0.0000e+00 - fp: 11743.0000 - tn: 0.0000e+00 - tp: 11810.0909 - precision: 0.5022 - recall: 1.0000 - accuracy: 0.5022 - val_loss: 2.4635 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8256 - fn: 0.0000e+00 - fp: 11765.0909 - tn: 0.0000e+00 - tp: 11788.0000 - precision: 0.5008 - recall: 1.0000 - accuracy: 0.5008 - val_loss: 2.4259 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7946 - fn: 0.0000e+00 - fp: 11760.3636 - tn: 0.0000e+00 - tp: 11792.7273 - precision: 0.5016 - recall: 1.0000 - accuracy: 0.5016 - val_loss: 2.3743 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.7953 - fn: 0.0000e+00 - fp: 11770.4545 - tn: 0.0000e+00 - tp: 11782.6364 - precision: 0.5003 - recall: 1.0000 - accuracy: 0.5003 - val_loss: 2.2716 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.7906 - fn: 0.0000e+00 - fp: 11731.9091 - tn: 0.0000e+00 - tp: 11821.1818 - precision: 0.5026 - recall: 1.0000 - accuracy: 0.5026 - val_loss: 2.2785 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8144 - fn: 0.0000e+00 - fp: 11732.0909 - tn: 0.0000e+00 - tp: 11821.0000 - precision: 0.5038 - recall: 1.0000 - accuracy: 0.5038 - val_loss: 2.3544 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8271 - fn: 0.0000e+00 - fp: 11713.0909 - tn: 0.0000e+00 - tp: 11840.0000 - precision: 0.5039 - recall: 1.0000 - accuracy: 0.5039 - val_loss: 2.1799 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8337 - fn: 0.0000e+00 - fp: 11744.2727 - tn: 0.0000e+00 - tp: 11808.8182 - precision: 0.5016 - recall: 1.0000 - accuracy: 0.5016 - val_loss: 2.2303 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8025 - fn: 0.0000e+00 - fp: 11783.1818 - tn: 0.0000e+00 - tp: 11769.9091 - precision: 0.4990 - recall: 1.0000 - accuracy: 0.4990 - val_loss: 2.2264 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7894 - fn: 0.0000e+00 - fp: 11740.5455 - tn: 0.0000e+00 - tp: 11812.5455 - precision: 0.5030 - recall: 1.0000 - accuracy: 0.5030 - val_loss: 2.4123 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7859 - fn: 0.0000e+00 - fp: 11788.8182 - tn: 0.0000e+00 - tp: 11764.2727 - precision: 0.4995 - recall: 1.0000 - accuracy: 0.4995 - val_loss: 2.5733 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8202 - fn: 0.0000e+00 - fp: 11765.2727 - tn: 0.0000e+00 - tp: 11787.8182 - precision: 0.5012 - recall: 1.0000 - accuracy: 0.5012 - val_loss: 2.1970 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.7979 - fn: 0.0000e+00 - fp: 11780.4545 - tn: 0.0000e+00 - tp: 11772.6364 - precision: 0.4984 - recall: 1.0000 - accuracy: 0.4984 - val_loss: 2.3576 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8011 - fn: 0.0000e+00 - fp: 11764.0000 - tn: 0.0000e+00 - tp: 11789.0909 - precision: 0.4998 - recall: 1.0000 - accuracy: 0.4998 - val_loss: 2.3637 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.7851 - fn: 0.0000e+00 - fp: 11768.0909 - tn: 0.0000e+00 - tp: 11785.0000 - precision: 0.5001 - recall: 1.0000 - accuracy: 0.5001 - val_loss: 2.3281 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7943 - fn: 0.0000e+00 - fp: 11733.8182 - tn: 0.0000e+00 - tp: 11819.2727 - precision: 0.5026 - recall: 1.0000 - accuracy: 0.5026 - val_loss: 2.2723 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8093 - fn: 0.0000e+00 - fp: 11766.6364 - tn: 0.0000e+00 - tp: 11786.4545 - precision: 0.5005 - recall: 1.0000 - accuracy: 0.5005 - val_loss: 2.2478 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8015 - fn: 0.0000e+00 - fp: 11760.7273 - tn: 0.0000e+00 - tp: 11792.3636 - precision: 0.5005 - recall: 1.0000 - accuracy: 0.5005 - val_loss: 2.2243 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.7953 - fn: 0.0000e+00 - fp: 11741.0909 - tn: 0.0000e+00 - tp: 11812.0000 - precision: 0.5027 - recall: 1.0000 - accuracy: 0.5027 - val_loss: 2.3613 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7955 - fn: 0.0000e+00 - fp: 11745.0909 - tn: 0.0000e+00 - tp: 11808.0000 - precision: 0.5009 - recall: 1.0000 - accuracy: 0.5009 - val_loss: 2.3583 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.7998 - fn: 0.0000e+00 - fp: 11794.3636 - tn: 0.0000e+00 - tp: 11758.7273 - precision: 0.4976 - recall: 1.0000 - accuracy: 0.4976 - val_loss: 2.4288 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7951 - fn: 0.0000e+00 - fp: 11790.6364 - tn: 0.0000e+00 - tp: 11762.4545 - precision: 0.4974 - recall: 1.0000 - accuracy: 0.4974 - val_loss: 2.3553 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8031 - fn: 0.0000e+00 - fp: 11766.3636 - tn: 0.0000e+00 - tp: 11786.7273 - precision: 0.4993 - recall: 1.0000 - accuracy: 0.4993 - val_loss: 2.3997 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8093 - fn: 0.0000e+00 - fp: 11751.3636 - tn: 0.0000e+00 - tp: 11801.7273 - precision: 0.5023 - recall: 1.0000 - accuracy: 0.5023 - val_loss: 2.2886 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 2.7969 - fn: 0.0000e+00 - fp: 11734.7273 - tn: 0.0000e+00 - tp: 11818.3636 - precision: 0.5026 - recall: 1.0000 - accuracy: 0.5026 - val_loss: 2.2218 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8017 - fn: 0.0000e+00 - fp: 11791.1818 - tn: 0.0000e+00 - tp: 11761.9091 - precision: 0.5002 - recall: 1.0000 - accuracy: 0.5002 - val_loss: 2.3099 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7639 - fn: 0.0000e+00 - fp: 11740.6364 - tn: 0.0000e+00 - tp: 11812.4545 - precision: 0.5022 - recall: 1.0000 - accuracy: 0.5022 - val_loss: 2.4551 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7768 - fn: 0.0000e+00 - fp: 11749.9091 - tn: 0.0000e+00 - tp: 11803.1818 - precision: 0.5011 - recall: 1.0000 - accuracy: 0.5011 - val_loss: 2.3129 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.8017 - fn: 0.0000e+00 - fp: 11753.6364 - tn: 0.0000e+00 - tp: 11799.4545 - precision: 0.5004 - recall: 1.0000 - accuracy: 0.5004 - val_loss: 2.5644 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 2.8588 - fn: 0.0000e+00 - fp: 11811.8182 - tn: 0.0000e+00 - tp: 11741.2727 - precision: 0.4969 - recall: 1.0000 - accuracy: 0.4969 - val_loss: 2.4499 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 2.8094 - fn: 0.0000e+00 - fp: 11732.9091 - tn: 0.0000e+00 - tp: 11820.1818 - precision: 0.5020 - recall: 1.0000 - accuracy: 0.5020 - val_loss: 2.2685 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 14ms/step - loss: 2.7946 - fn: 0.0000e+00 - fp: 11761.7273 - tn: 0.0000e+00 - tp: 11791.3636 - precision: 0.5009 - recall: 1.0000 - accuracy: 0.5009 - val_loss: 2.3777 - val_fn: 0.0000e+00 - val_fp: 4697.0000 - val_tn: 0.0000e+00 - val_tp: 4649.0000 - val_precision: 0.4974 - val_recall: 1.0000 - val_accuracy: 0.4974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a7004e208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF5rGE2Z9DFT",
        "outputId": "acc95af3-f61d-47d3-f89e-fcb72fdd6cae"
      },
      "source": [
        "np.set_printoptions(suppress=True)\r\n",
        "res = model.predict(test_features).reshape(1, -1)\r\n",
        "np.array(np.unique(res, return_counts=True)).T"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1., 9346.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhJyEr8YumaX",
        "outputId": "65116d08-9ecf-49c9-c535-15236fae5bda"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1024)              33792     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 722,945\n",
            "Trainable params: 722,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjPoZMvokczz"
      },
      "source": [
        "# homework\r\n",
        "# Solve the clasification problem. \r\n",
        "# handle data imbalance issue\r\n",
        "# Design DL network to classify\r\n",
        "# Print loss, F1 score and ROC\r\n",
        "# Visualize loss in training and test data using matplotlib\r\n",
        "# Send the link of colab to amritansh.48@gmail.com"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}